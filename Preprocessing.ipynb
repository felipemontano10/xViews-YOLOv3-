{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipemontanocampos/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/felipemontanocampos/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/felipemontanocampos/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/felipemontanocampos/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/felipemontanocampos/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/felipemontanocampos/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/felipemontanocampos/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/felipemontanocampos/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/felipemontanocampos/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/felipemontanocampos/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/felipemontanocampos/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/felipemontanocampos/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import tensorflow as tf\n",
    "import io\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import logging\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import skimage.filters as filters\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder= 'imagedata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}\n",
    "boxes = {}\n",
    "train_chips = 0\n",
    "test_chips = 0\n",
    "\n",
    "#Parameters\n",
    "train_writer = tf.io.TFRecordWriter(\"xview_train.record\")\n",
    "test_writer = tf.io.TFRecordWriter(\"xview_test.record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent=0.2\n",
    "SAVE_IMAGES= True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read label data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(fname=\"xView_train.geojson\"):\n",
    "    \n",
    "    with open(fname) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    coords = np.zeros((len(data['features']),4))\n",
    "    chips = np.zeros((len(data['features'])),dtype=\"object\")\n",
    "    classes = np.zeros((len(data['features'])))\n",
    "    \n",
    "    for i in range(len(data['features'])):\n",
    "        if data['features'][i]['properties']['bounds_imcoords'] != []:\n",
    "            b_id = data['features'][i]['properties']['image_id']\n",
    "            val = np.array([int(num) for num in data['features'][i]['properties']['bounds_imcoords'].split(\",\")])\n",
    "            chips[i] = b_id\n",
    "            classes[i] = data['features'][i]['properties']['type_id']\n",
    "            coords[i] = val\n",
    "        else:\n",
    "            chips[i] = 'None'\n",
    "            \n",
    "    return coords, chips, classes, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, chips, classes, data= get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(601937,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chips.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read image data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob.glob(image_folder + \"*.tif\")\n",
    "fnames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(fname):    \n",
    "    \"\"\"\n",
    "    Get an image from a filepath in ndarray format\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chip_image(img,coords,classes,shape=(300,300)):\n",
    "    \"\"\"\n",
    "    Chip an image and get relative coordinates and classes.  Bounding boxes that pass into\n",
    "        multiple chips are clipped: each portion that is in a chip is labeled. For example,\n",
    "        half a building will be labeled if it is cut off in a chip. If there are no boxes,\n",
    "        the boxes array will be [[0,0,0,0]] and classes [0].\n",
    "        Note: This chip_image method is only tested on xView data-- there are some image manipulations that can mess up different images.\n",
    "    Args:\n",
    "        img: the image to be chipped in array format\n",
    "        coords: an (N,4) array of bounding box coordinates for that image\n",
    "        classes: an (N,1) array of classes for each bounding box\n",
    "        shape: an (W,H) tuple indicating width and height of chips\n",
    "    Output:\n",
    "        An image array of shape (M,W,H,C), where M is the number of chips,\n",
    "        W and H are the dimensions of the image, and C is the number of color\n",
    "        channels.  Also returns boxes and classes dictionaries for each corresponding chip.\n",
    "    \"\"\"\n",
    "    height,width,_ = img.shape\n",
    "    wn,hn = shape\n",
    "    \n",
    "    w_num,h_num = (int(width/wn),int(height/hn))\n",
    "    images = np.zeros((w_num*h_num,hn,wn,3))\n",
    "    total_boxes = {}\n",
    "    total_classes = {}\n",
    "    \n",
    "    k = 0\n",
    "    for i in range(w_num):\n",
    "        for j in range(h_num):\n",
    "            x = np.logical_or( np.logical_and((coords[:,0]<((i+1)*wn)),(coords[:,0]>(i*wn))),\n",
    "                               np.logical_and((coords[:,2]<((i+1)*wn)),(coords[:,2]>(i*wn))))\n",
    "            out = coords[x]\n",
    "            y = np.logical_or( np.logical_and((out[:,1]<((j+1)*hn)),(out[:,1]>(j*hn))),\n",
    "                               np.logical_and((out[:,3]<((j+1)*hn)),(out[:,3]>(j*hn))))\n",
    "            outn = out[y]\n",
    "            out = np.transpose(np.vstack((np.clip(outn[:,0]-(wn*i),0,wn),\n",
    "                                          np.clip(outn[:,1]-(hn*j),0,hn),\n",
    "                                          np.clip(outn[:,2]-(wn*i),0,wn),\n",
    "                                          np.clip(outn[:,3]-(hn*j),0,hn))))\n",
    "            box_classes = classes[x][y]\n",
    "        \n",
    "            if out.shape[0] != 0:\n",
    "                total_boxes[k] = out\n",
    "                total_classes[k] = box_classes\n",
    "            else:\n",
    "                total_boxes[k] = np.array([[0,0,0,0]])\n",
    "                total_classes[k] = np.array([0])\n",
    "            \n",
    "            chip = img[hn*j:hn*(j+1),wn*i:wn*(i+1),:3]\n",
    "            images[k]=chip\n",
    "            \n",
    "            k = k + 1\n",
    "    \n",
    "    return images.astype(np.uint8),total_boxes,total_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToJpeg(im):\n",
    "    \"\"\"\n",
    "    Converts an image array into an encoded JPEG string.\n",
    "    Args:\n",
    "        im: an image array\n",
    "    Output:\n",
    "        an encoded byte string containing the converted JPEG image.\n",
    "    \"\"\"\n",
    "    with io.BytesIO() as f:\n",
    "        im = Image.fromarray(im)\n",
    "        im.save(f, format='JPEG')\n",
    "        return f.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def int64_list_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_list_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def float_list_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_example(img, boxes, class_num):\n",
    "    \"\"\"\n",
    "    Converts a single image with respective boxes into a TFExample.  Multiple TFExamples make up a TFRecord.\n",
    "    Args:\n",
    "        img: an image array\n",
    "        boxes: an array of bounding boxes for the given image\n",
    "        class_num: an array of class numbers for each bouding box\n",
    "    Output:\n",
    "        A TFExample containing encoded image data, scaled bounding boxes with classes, and other metadata.\n",
    "    \"\"\"\n",
    "    encoded = convertToJpeg(img)\n",
    "\n",
    "    width = img.shape[0]\n",
    "    height = img.shape[1]\n",
    "\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "    \n",
    "    for ind,box in enumerate(boxes):\n",
    "        xmin.append(box[0] / width)\n",
    "        ymin.append(box[1] / height)\n",
    "        xmax.append(box[2] / width)\n",
    "        ymax.append(box[3] / height) \n",
    "        classes.append(int(class_num[ind]))\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image/height': int64_feature(height),\n",
    "            'image/width': int64_feature(width),\n",
    "            'image/encoded': bytes_feature(encoded),\n",
    "            'image/format': bytes_feature('jpeg'.encode('utf8')),\n",
    "            'image/object/bbox/xmin': float_list_feature(xmin),\n",
    "            'image/object/bbox/xmax': float_list_feature(xmax),\n",
    "            'image/object/bbox/ymin': float_list_feature(ymin),\n",
    "            'image/object/bbox/ymax': float_list_feature(ymax),\n",
    "            'image/object/class/label': int64_list_feature(classes),\n",
    "    }))\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_images_and_boxes_classes(im,box,cls):\n",
    "    \"\"\"\n",
    "    Shuffles images, boxes, and classes, while keeping relative matching indices\n",
    "    Args:\n",
    "        im: an array of images\n",
    "        box: an array of bounding box coordinates ([xmin,ymin,xmax,ymax])\n",
    "        cls: an array of classes\n",
    "    Output:\n",
    "        Shuffle image, boxes, and classes arrays, respectively\n",
    "    \"\"\"\n",
    "    assert len(im) == len(box)\n",
    "    assert len(box) == len(cls)\n",
    "    \n",
    "    perm = np.random.permutation(len(im))\n",
    "    out_b = {}\n",
    "    out_c = {}\n",
    "    \n",
    "    k = 0 \n",
    "    for ind in perm:\n",
    "        out_b[k] = box[ind]\n",
    "        out_c[k] = cls[ind]\n",
    "        k = k + 1\n",
    "    return im[perm], out_b, out_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image(image,bbox):\n",
    "    \"\"\"\n",
    "    Shift an image by a random amount on the x and y axis drawn from discrete  \n",
    "        uniform distribution with parameter min(shape/10)\n",
    "    Args:\n",
    "        image: the image to be shifted in array format\n",
    "        bbox: an (N,4) array of boxes for the image\n",
    "    Output:\n",
    "        The shifted image and corresponding boxes\n",
    "    \"\"\"\n",
    "    shape = image.shape[:2]\n",
    "    maxdelta = min(shape)/10\n",
    "    dx,dy = np.random.randint(-maxdelta,maxdelta,size=(2))\n",
    "    newimg = np.zeros(image.shape,dtype=np.uint8)\n",
    "    \n",
    "    nb = []\n",
    "    for box in bbox:\n",
    "        xmin,xmax = np.clip((box[0]+dy,box[2]+dy),0,shape[1])\n",
    "        ymin,ymax = np.clip((box[1]+dx,box[3]+dx),0,shape[0])\n",
    "\n",
    "        #we only add the box if they are not all 0\n",
    "        if not(xmin==0 and xmax ==0 and ymin==0 and ymax ==0):\n",
    "            nb.append([xmin,ymin,xmax,ymax])\n",
    "    \n",
    "    newimg[max(dx,0):min(image.shape[0],image.shape[0]+dx),\n",
    "           max(dy,0):min(image.shape[1],image.shape[1]+dy)] = \\\n",
    "    image[max(-dx,0):min(image.shape[0],image.shape[0]-dx),\n",
    "          max(-dy,0):min(image.shape[1],image.shape[1]-dy)]\n",
    "    \n",
    "    return newimg, nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image_and_boxes(img, deg, pivot, boxes):\n",
    "    \"\"\"\n",
    "    Rotates an image and corresponding bounding boxes.  Bounding box rotations are kept axis-aligned,\n",
    "        so multiples of non 90-degrees changes the area of the bounding box.\n",
    "    Args:\n",
    "        img: the image to be rotated in array format\n",
    "        deg: an integer representing degree of rotation\n",
    "        pivot: the axis of rotation. By default should be the center of an image, but this can be changed.\n",
    "        boxes: an (N,4) array of boxes for the image\n",
    "    Output:\n",
    "        Returns the rotated image array along with correspondingly rotated bounding boxes\n",
    "    \"\"\"\n",
    "\n",
    "    if deg < 0:\n",
    "        deg = 360-deg\n",
    "    deg = int(deg)\n",
    "        \n",
    "    angle = 360-deg\n",
    "    padX = [img.shape[0] - pivot[0], pivot[0]]\n",
    "    padY = [img.shape[1] - pivot[1], pivot[1]]\n",
    "    imgP = np.pad(img, [padY, padX, [0,0]], 'constant').astype(np.uint8)\n",
    "    #scipy ndimage rotate takes ~.7 seconds\n",
    "    #imgR = ndimage.rotate(imgP, angle, reshape=False)\n",
    "    #PIL rotate uses ~.01 seconds\n",
    "    imgR = Image.fromarray(imgP).rotate(angle)\n",
    "    imgR = np.array(imgR)\n",
    "    \n",
    "    theta = deg * (np.pi/180)\n",
    "    R = np.array([[np.cos(theta),-np.sin(theta)],[np.sin(theta),np.cos(theta)]])\n",
    "    #  [(cos(theta), -sin(theta))] DOT [xmin, xmax] = [xmin*cos(theta) - ymin*sin(theta), xmax*cos(theta) - ymax*sin(theta)]\n",
    "    #  [sin(theta), cos(theta)]        [ymin, ymax]   [xmin*sin(theta) + ymin*cos(theta), xmax*cos(theta) + ymax*cos(theta)]\n",
    "\n",
    "    newboxes = []\n",
    "    for box in boxes:\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        #The 'x' values are not centered by the x-center (shape[0]/2)\n",
    "        #but rather the y-center (shape[1]/2)\n",
    "        \n",
    "        xmin -= pivot[1]\n",
    "        xmax -= pivot[1]\n",
    "        ymin -= pivot[0]\n",
    "        ymax -= pivot[0]\n",
    "\n",
    "        bfull = np.array([ [xmin,xmin,xmax,xmax] , [ymin,ymax,ymin,ymax]])\n",
    "        c = np.dot(R,bfull) \n",
    "        c[0] += pivot[1]\n",
    "        c[0] = np.clip(c[0],0,img.shape[1])\n",
    "        c[1] += pivot[0]\n",
    "        c[1] = np.clip(c[1],0,img.shape[0])\n",
    "        \n",
    "        if np.all(c[1] == img.shape[0]) or np.all(c[1] == 0):\n",
    "            c[0] = [0,0,0,0]\n",
    "        if np.all(c[0] == img.shape[1]) or np.all(c[0] == 0):\n",
    "            c[1] = [0,0,0,0]\n",
    "\n",
    "        newbox = np.array([np.min(c[0]),np.min(c[1]),np.max(c[0]),np.max(c[1])]).astype(np.int64)\n",
    "\n",
    "        if not (np.all(c[1] == 0) and np.all(c[0] == 0)):\n",
    "            newboxes.append(newbox)\n",
    "    \n",
    "    return imgR[padY[0] : -padY[1], padX[0] : -padX[1]], newboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salt_and_pepper(img,prob=.005):\n",
    "    \"\"\"\n",
    "    Applies salt and pepper noise to an image with given probability for both.\n",
    "    Args:\n",
    "        img: the image to be augmented in array format\n",
    "        prob: the probability of applying noise to the image\n",
    "    Output:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "\n",
    "    newimg = np.copy(img)\n",
    "    whitemask = np.random.randint(0,int((1-prob)*200),size=img.shape[:2])\n",
    "    blackmask = np.random.randint(0,int((1-prob)*200),size=img.shape[:2])\n",
    "    newimg[whitemask==0] = 255\n",
    "    newimg[blackmask==0] = 0\n",
    "        \n",
    "    return newimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img, max_sigma=1.5):\n",
    "    \"\"\"\n",
    "    Use a gaussian filter to blur an image\n",
    "    Args:\n",
    "        img: image to be augmented in array format\n",
    "        max_sigma: the maximum variance for gaussian blurring\n",
    "    Output:\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "    return (filters.gaussian(img,np.random.random()*max_sigma,multichannel=True)*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxes(img,boxes):\n",
    "    \"\"\"\n",
    "    A helper function to draw bounding box rectangles on images\n",
    "    Args:\n",
    "        img: image to be drawn on in array format\n",
    "        boxes: An (N,4) array of bounding boxes\n",
    "    Output:\n",
    "        Image with drawn bounding boxes\n",
    "    \"\"\"\n",
    "    source = Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(source)\n",
    "    w2,h2 = (img.shape[0],img.shape[1])\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for b in boxes:\n",
    "        xmin,ymin,xmax,ymax = b\n",
    "        \n",
    "        for j in range(3):\n",
    "            draw.rectangle(((xmin+j, ymin+j), (xmax+j, ymax+j)), outline=\"red\")\n",
    "    return source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in fnames:\n",
    "            \n",
    "            name = fname.split(\"\\\\\")[-1]\n",
    "            arr = get_image(fname)\n",
    "\n",
    "            im,box,classes_final = chip_image(arr,coords[chips==name],classes[chips==name])\n",
    "            im,box,classes_final = shuffle_images_and_boxes_classes(im,box,classes_final)\n",
    "            split_ind = int(im.shape[0] * test_percent)\n",
    "            \n",
    "            \n",
    "            for idx, image in enumerate(im):\n",
    "                tf_example = to_tf_example(image,box[idx],classes_final[idx])\n",
    "\n",
    "                #Check to make sure that the TF_Example has valid bounding boxes.  \n",
    "                #If there are no valid bounding boxes, then don't save the image to the TFRecord.\n",
    "                float_list_value = tf_example.features.feature['image/object/bbox/xmin'].float_list.value\n",
    "                \n",
    "                if np.array(float_list_value).any():\n",
    "                  #  tot_box+=np.array(float_list_value).shape[0]\n",
    "                    \n",
    "                    if idx < split_ind:\n",
    "                        test_writer.write(tf_example.SerializeToString())\n",
    "                        test_chips+=1\n",
    "                    else:\n",
    "                        train_writer.write(tf_example.SerializeToString())\n",
    "                        train_chips += 1\n",
    "                 \n",
    "                \n",
    "                for extra in range(3):\n",
    "                    center = np.array([int(image.shape[0]/2),int(image.shape[1]/2)])\n",
    "                    deg = np.random.randint(-10,10)\n",
    "                    #deg = np.random.normal()*30\n",
    "                    newimg = salt_and_pepper(gaussian_blur(image))\n",
    "\n",
    "                    #.3 probability for each of shifting vs rotating vs shift(rotate(image))\n",
    "                    p = np.random.randint(0,3)\n",
    "                    if p == 0:\n",
    "                        newimg,nb = shift_image(newimg,box[idx])\n",
    "                    elif p == 1:\n",
    "                        newimg,nb = rotate_image_and_boxes(newimg,deg,center,box[idx])\n",
    "                    elif p == 2:\n",
    "                        newimg,nb = rotate_image_and_boxes(newimg,deg,center,box[idx])\n",
    "                        newimg,nb = shift_image(newimg,nb)\n",
    "\n",
    "\n",
    "                    newimg = (newimg).astype(np.uint8)\n",
    "                    \n",
    "                    if idx%100 == 0 and SAVE_IMAGES:\n",
    "                        Image.fromarray(newimg).save('process/img_%s_%s.png'%(name.replace(\"/\",\"_\"),extra))\n",
    "\n",
    "                    if len(nb) > 0:\n",
    "                        tf_example = to_tf_example(newimg,nb,classes_final[idx])\n",
    "\n",
    "                        #Don't count augmented chips for chip indices\n",
    "                        if idx < split_ind:\n",
    "                            test_writer.write(tf_example.SerializeToString())\n",
    "                            test_chips += 1\n",
    "                        else:\n",
    "                            train_writer.write(tf_example.SerializeToString())\n",
    "                            train_chips+=1\n",
    "                    else:\n",
    "                        if SAVE_IMAGES:\n",
    "                            draw_bboxes(newimg,nb).save('process/img_nobox_%s_%s.png'%(name.replace(\"/\",\"_\"),extra))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "test_writer.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TFRecordWriter' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-683b0f9a0df7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_writer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'TFRecordWriter' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in train_writer:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
